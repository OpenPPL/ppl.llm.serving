// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: llm.proto

#include "llm.pb.h"
#include "llm.grpc.pb.h"

#include <functional>
#include <grpcpp/support/async_stream.h>
#include <grpcpp/support/async_unary_call.h>
#include <grpcpp/impl/channel_interface.h>
#include <grpcpp/impl/client_unary_call.h>
#include <grpcpp/support/client_callback.h>
#include <grpcpp/support/message_allocator.h>
#include <grpcpp/support/method_handler.h>
#include <grpcpp/impl/rpc_service_method.h>
#include <grpcpp/support/server_callback.h>
#include <grpcpp/impl/server_callback_handlers.h>
#include <grpcpp/server_context.h>
#include <grpcpp/impl/service_type.h>
#include <grpcpp/support/sync_stream.h>
namespace ppl {
namespace llm {
namespace proto {

static const char* LLMService_method_names[] = {
  "/ppl.llm.proto.LLMService/Generation",
};

std::unique_ptr< LLMService::Stub> LLMService::NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options) {
  (void)options;
  std::unique_ptr< LLMService::Stub> stub(new LLMService::Stub(channel, options));
  return stub;
}

LLMService::Stub::Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options)
  : channel_(channel), rpcmethod_Generation_(LLMService_method_names[0], options.suffix_for_stats(),::grpc::internal::RpcMethod::SERVER_STREAMING, channel)
  {}

::grpc::ClientReader< ::ppl::llm::proto::Response>* LLMService::Stub::GenerationRaw(::grpc::ClientContext* context, const ::ppl::llm::proto::BatchedRequest& request) {
  return ::grpc::internal::ClientReaderFactory< ::ppl::llm::proto::Response>::Create(channel_.get(), rpcmethod_Generation_, context, request);
}

void LLMService::Stub::async::Generation(::grpc::ClientContext* context, const ::ppl::llm::proto::BatchedRequest* request, ::grpc::ClientReadReactor< ::ppl::llm::proto::Response>* reactor) {
  ::grpc::internal::ClientCallbackReaderFactory< ::ppl::llm::proto::Response>::Create(stub_->channel_.get(), stub_->rpcmethod_Generation_, context, request, reactor);
}

::grpc::ClientAsyncReader< ::ppl::llm::proto::Response>* LLMService::Stub::AsyncGenerationRaw(::grpc::ClientContext* context, const ::ppl::llm::proto::BatchedRequest& request, ::grpc::CompletionQueue* cq, void* tag) {
  return ::grpc::internal::ClientAsyncReaderFactory< ::ppl::llm::proto::Response>::Create(channel_.get(), cq, rpcmethod_Generation_, context, request, true, tag);
}

::grpc::ClientAsyncReader< ::ppl::llm::proto::Response>* LLMService::Stub::PrepareAsyncGenerationRaw(::grpc::ClientContext* context, const ::ppl::llm::proto::BatchedRequest& request, ::grpc::CompletionQueue* cq) {
  return ::grpc::internal::ClientAsyncReaderFactory< ::ppl::llm::proto::Response>::Create(channel_.get(), cq, rpcmethod_Generation_, context, request, false, nullptr);
}

LLMService::Service::Service() {
  AddMethod(new ::grpc::internal::RpcServiceMethod(
      LLMService_method_names[0],
      ::grpc::internal::RpcMethod::SERVER_STREAMING,
      new ::grpc::internal::ServerStreamingHandler< LLMService::Service, ::ppl::llm::proto::BatchedRequest, ::ppl::llm::proto::Response>(
          [](LLMService::Service* service,
             ::grpc::ServerContext* ctx,
             const ::ppl::llm::proto::BatchedRequest* req,
             ::grpc::ServerWriter<::ppl::llm::proto::Response>* writer) {
               return service->Generation(ctx, req, writer);
             }, this)));
}

LLMService::Service::~Service() {
}

::grpc::Status LLMService::Service::Generation(::grpc::ServerContext* context, const ::ppl::llm::proto::BatchedRequest* request, ::grpc::ServerWriter< ::ppl::llm::proto::Response>* writer) {
  (void) context;
  (void) request;
  (void) writer;
  return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
}


}  // namespace ppl
}  // namespace llm
}  // namespace proto

